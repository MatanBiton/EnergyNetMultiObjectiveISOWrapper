{
  "experiment_name": "test_fixed",
  "training_time": 8.709607124328613,
  "total_timesteps": 5000,
  "total_episodes": 104,
  "final_evaluation": {
    "mean": -1943.5068287730217,
    "std": 9.790090317434085,
    "rewards": [
      -1986.180843114853,
      -1941.2608280181885,
      -1941.2608280181885,
      -1941.2608280181885,
      -1941.2608280181885,
      -1941.2608280181885,
      -1941.2608280181885,
      -1941.2608280181885,
      -1941.2608280181885,
      -1941.2608280181885,
      -1941.2608280181885,
      -1941.2608280181885,
      -1941.2608280181885,
      -1941.2608280181885,
      -1941.2608280181885,
      -1941.2608280181885,
      -1941.2608280181885,
      -1941.2608280181885,
      -1941.2608280181885,
      -1941.2608280181885
    ]
  },
  "best_evaluation": -Infinity,
  "episode_rewards": [
    283.93272890150547,
    -64.8461800031364,
    257.7767013460398,
    19.67069762945175,
    -3152.9178980588913,
    819.6772782206535,
    -1820.9043739438057,
    -1420.3435587214772,
    253.5663725528866,
    425.1960387825966,
    -2261.345633402467,
    -1251.3314999639988,
    -895.7154349982738,
    447.8611045256257,
    -1066.5699951201677,
    352.6488869190216,
    757.8588671088219,
    -1820.1629407554865,
    -930.7702343706042,
    -2244.382038012147,
    -1705.1908275485039,
    98.71580120921135,
    -2199.910545349121,
    -1364.0584058612585,
    -3027.669730782509,
    -1749.6866201534867,
    -317.390887722373,
    -32.95902345329523,
    -274.0802233815193,
    91.25004623830318,
    611.8203510446474,
    -193.76881258189678,
    -1992.319037720561,
    -1864.59173553437,
    -464.1011249497533,
    -1541.527128458023,
    -337.7187589369714,
    112.73435217142105,
    -659.4154102057219,
    -715.6448511648923,
    -1948.594847485423,
    45.541692435741425,
    548.0755669474602,
    967.4947794266045,
    -2533.2596645392478,
    -2955.096285449341,
    -713.8625419288874,
    -261.7780771404505,
    -1692.2300488725305,
    914.14886328578,
    860.9053296148777,
    -772.2996693626046,
    -2234.789488583803,
    -823.7227140329778,
    -1.9395280703902245,
    -979.4597596749663,
    432.5044302344322,
    -725.2135757729411,
    -2849.233413884416,
    -1593.9662184268236,
    -1774.5730923116207,
    -1455.2481617033482,
    -756.5931590348482,
    -51.70533365383744,
    -2041.7865543216467,
    96.0621333308518,
    -2176.449685573578,
    -1309.6638531535864,
    402.5400804281235,
    465.05396300554276,
    -2460.415254563093,
    918.7026578783989,
    -231.89241507463157,
    -3389.983893625438,
    -327.4347457587719,
    627.2980692982674,
    -1729.2557059824467,
    582.2978670746088,
    -1938.0169663615525,
    -2014.8090692162514,
    -1889.0599382221699,
    422.03213688731194,
    279.3507394492626,
    738.8204553872347,
    -2629.7389172911644,
    -639.3265707679093,
    -135.0732145756483,
    -875.0452913492918,
    -193.56612180173397,
    -714.9163013398647,
    -987.3734437525272,
    -1602.3532735183835,
    -1153.1604811698198,
    -1744.9495526505634,
    -2734.88145044446,
    -1226.967143498361,
    -3279.2970642335713,
    -420.2869474887848,
    -825.0785241127014,
    -2378.5236024707556,
    -2199.022771716118,
    -238.0217428393662,
    662.9333348870277,
    224.71468803286552
  ],
  "episode_lengths": [
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48,
    48
  ],
  "evaluation_results": [],
  "training_metrics": [],
  "model_paths": {
    "final": "pcs_experiments/models/test_fixed_final.pth",
    "best": "pcs_experiments/models/test_fixed_best.pth"
  },
  "config": {
    "trained_iso_model_path": "/home/matan.biton/EnergyNetMultiObjectiveISOWrapper/multi_objecctive_iso_algo/mo_sac_testing/models/train_energynet_no_opt_0_action_with_disp_1754349507_110000.pth",
    "state_dim": 4,
    "action_dim": 1,
    "action_bounds": [
      -10.0,
      10.0
    ],
    "agent_params": {
      "actor_lr": 0.0003,
      "critic_lr": 0.0003,
      "alpha_lr": 0.0003,
      "gamma": 0.99,
      "tau": 0.005,
      "alpha": 0.2,
      "auto_tune_alpha": true,
      "buffer_capacity": 1000000,
      "batch_size": 42,
      "use_lr_annealing": false,
      "lr_annealing_type": "cosine",
      "lr_annealing_steps": null,
      "use_reward_scaling": false,
      "use_orthogonal_init": false,
      "use_value_clipping": false
    }
  }
}